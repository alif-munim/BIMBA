{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04a4cda5-3116-4548-80a1-25c454052768",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c9f0e2-0dfd-41d8-b6c0-c932885a1709",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python-headless  # lighter, no GUI deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a7a71eb-2ac3-4346-8261-150353bdee0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "215695b2-c6b4-417a-8b4a-1e854e924ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3, json, pandas as pd, itertools\n",
    "from tqdm.notebook import tqdm            # Jupyter/HTML bar\n",
    "\n",
    "s3 = boto3.client(\"s3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfd06ab8-61dc-4716-9baa-54e565b38aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# helpers\n",
    "# ------------------------------------------------------------\n",
    "def body_iter_lines(uri: str):\n",
    "    bucket, key = uri.replace(\"s3://\", \"\", 1).split(\"/\", 1)\n",
    "    return boto3.client(\"s3\").get_object(Bucket=bucket, Key=key)[\"Body\"].iter_lines()\n",
    "\n",
    "def row_count(uri: str) -> int:\n",
    "    \"One streaming pass → exact line count.\"\n",
    "    return sum(1 for _ in body_iter_lines(uri))\n",
    "\n",
    "def stream_jsonl(uri: str):\n",
    "    for raw in body_iter_lines(uri):\n",
    "        if raw:\n",
    "            yield json.loads(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d67bb61a-1866-48f1-a41e-a7c9e244108d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def _split_bullets(block: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Turn a multiline block that starts with \"- \" and uses \"\\n- \"\n",
    "    into a list of clean strings.\n",
    "    \"\"\"\n",
    "    if not block:\n",
    "        return []\n",
    "\n",
    "    # Remove the first leading dash and any leading/trailing whitespace\n",
    "    block = block.lstrip(\"-\").strip()\n",
    "\n",
    "    # Split on newline followed by dash (with optional spaces)\n",
    "    items = re.split(r\"\\n-\\s*\", block)\n",
    "\n",
    "    # Final strip for each item, drop empties\n",
    "    return [x.strip() for x in items if x.strip()]\n",
    "\n",
    "def parse_messages_to_df(df: pd.DataFrame, *, col: str = \"messages\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extract SID, study-findings, numeric-measurements (as lists),\n",
    "    and META tags from the 'messages' column.\n",
    "    \"\"\"\n",
    "    rows_out = []\n",
    "\n",
    "    for row in df[col]:\n",
    "        # 1 · pull first user message text ---------------------------------\n",
    "        user_parts = next((m[\"content\"] for m in row if m.get(\"role\") == \"user\"), [])\n",
    "        full_text  = \"\\n\".join(p[\"text\"] for p in user_parts if \"text\" in p)\n",
    "\n",
    "        # 2 · regex captures -----------------------------------------------\n",
    "        sid          = re.search(r\"<SID:([^>]+)>\", full_text)\n",
    "        study_find   = re.search(r\"Study findings:\\n(.*?)\\n\\nNumeric measurements:\", full_text, re.S)\n",
    "        numeric_meas = re.search(r\"Numeric measurements:\\n(.*?)\\n\\n<META_START>\",   full_text, re.S)\n",
    "        meta_tags    = re.search(r\"<META_START>\\n(.*?)\\n<META_END>\",                full_text, re.S)\n",
    "\n",
    "        # 3 · split the two blocks into lists ▼-----------------------------\n",
    "        study_list   = _split_bullets(study_find.group(1))   if study_find   else []\n",
    "        numeric_list = _split_bullets(numeric_meas.group(1)) if numeric_meas else []\n",
    "\n",
    "        rows_out.append({\n",
    "            \"sid\"           : sid.group(1).strip()        if sid       else None,\n",
    "            \"study_findings\": study_list,\n",
    "            \"numeric_meas\"  : numeric_list,\n",
    "            \"meta_tags\"     : meta_tags.group(1).strip()  if meta_tags else None,\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cded0bea-6772-4e25-baa9-e8134a7c79a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def is_tag_only_list(lst):\n",
    "    \"\"\"\n",
    "    True  → every element looks like a bare tag\n",
    "            e.g.  [\"LVH_obs\", \"AoV_sten_degree_SD_obs\"]\n",
    "    False → at least one element carries a value or a sentence\n",
    "            e.g.  [\"LVH_obs : mild\", \"The LV chamber size is normal.\"]\n",
    "    \"\"\"\n",
    "    if not isinstance(lst, list):\n",
    "        return False                 # guard for NaNs or bad types\n",
    "    return all((\":\" not in s) and (\".\" not in s) for s in lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f86a038-b3d4-4420-ab93-0672b4332bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, orjson, re\n",
    "sid_pat = re.compile(r\"<SID:([^>]+)>\")\n",
    "\n",
    "def parse_row(row):\n",
    "    # fast JSON load only if still a string\n",
    "    mi = orjson.loads(row.modelInput)  if isinstance(row.modelInput,  str) else row.modelInput\n",
    "    mo = orjson.loads(row.modelOutput) if isinstance(row.modelOutput, str) else row.modelOutput\n",
    "\n",
    "    # ── SID ──────────────────────────────────────────────────────────────\n",
    "    sid = None\n",
    "    for m in mi.get(\"messages\", ()):\n",
    "        for seg in m.get(\"content\", ()):\n",
    "            if isinstance(seg, dict):\n",
    "                m0 = sid_pat.search(seg.get(\"text\", \"\"))\n",
    "                if m0:\n",
    "                    sid = m0.group(1)\n",
    "                    break\n",
    "        if sid: break\n",
    "\n",
    "    # ── conversation text ───────────────────────────────────────────────\n",
    "    try:\n",
    "        conv = mo[\"output\"][\"message\"][\"content\"][0][\"text\"]\n",
    "    except Exception:\n",
    "        conv = None\n",
    "\n",
    "    return sid, conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af40135b-b9b3-4bba-b01b-d34884b75000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, json, orjson\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "COL       = \"conversations\"\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 1 · structural typos\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "_fix_struct = (\n",
    "    (re.compile(r'\"value=\"\\s*'),                       '\"value\":\"'),\n",
    "    (re.compile(r'\\{\"from\":\"(gpt|human)\",\\s*\"\"'),      r'{\"from\":\"\\1\",\"value\":\"'),\n",
    "    (re.compile(r'\\{\"from\":\"(gpt|human)\"\\s*:\\s*'),     r'{\"from\":\"\\1\",\"value\":')\n",
    ")\n",
    "\n",
    "def structural(txt: str) -> str:\n",
    "    for pat, repl in _fix_struct:\n",
    "        txt = pat.sub(repl, txt)\n",
    "    return txt\n",
    "\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 2 · escape control chars & lone back-slashes inside strings\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "_str_pat = re.compile(r'\"(?:[^\"\\\\]|\\\\.)*\"', re.S)        # every JSON string\n",
    "\n",
    "def _escape_ctrl(ch: str) -> str:\n",
    "    \"\"\"Map control char to JSON escape sequence.\"\"\"\n",
    "    if   ch == '\\n': return r'\\n'\n",
    "    elif ch == '\\r': return r'\\r'\n",
    "    elif ch == '\\t': return r'\\t'\n",
    "    else:            return f'\\\\u{ord(ch):04x}'\n",
    "\n",
    "_ctrl_pat = re.compile(r'[\\x00-\\x1F]')                   # 0–31\n",
    "\n",
    "def escape_in_quotes(txt: str) -> str:\n",
    "    def patch(m):\n",
    "        s = m.group(0)\n",
    "        s = _ctrl_pat.sub(lambda c: _escape_ctrl(c.group(0)), s)\n",
    "        s = re.sub(r'\\\\(?![\"\\\\/bfnrtu])', r'\\\\\\\\', s)     # lone \"\\\"\n",
    "        return s\n",
    "    return _str_pat.sub(patch, txt)\n",
    "\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 3 · convert raw → Python list   (None if truly truncated)\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "def to_list(raw: str):\n",
    "    try:                         # fast path\n",
    "        return orjson.loads(raw)\n",
    "    except orjson.JSONDecodeError:\n",
    "        fixed = escape_in_quotes(structural(raw))\n",
    "        try:\n",
    "            return json.loads(fixed)  # stdlib tolerates pretty well\n",
    "        except Exception:\n",
    "            return None               # still broken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0682e318-692e-4a0b-8f87-eb32d05a686d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Inspect Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02b000ff-55e0-4d26-815a-1a75f427e5ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d02912ed2c440f9a4f0f096677b9394",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "all jobs:   0%|          | 0/6 [00:00<?, ?file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca49329da978462cbdbd395dbccbbbad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "gen10:   0%|          | 0/50000 [00:00<?, ?rows/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4f5ca6f439b4e87aac869809e5d7fb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "gen10:   0%|          | 0/50000 [00:00<?, ?rows/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d32ce124e58490b83077643917a24ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "gen10:   0%|          | 0/50000 [00:00<?, ?rows/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e048060ca73406da9a3d30ea877a411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "gen10:   0%|          | 0/50000 [00:00<?, ?rows/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c938f5b0ecc4da09e920166ff4451dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "gen10:   0%|          | 0/50000 [00:00<?, ?rows/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f92dc95d4e1b41af8c0cf842f0422e66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "gen10:   0%|          | 0/16008 [00:00<?, ?rows/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "uris = [\n",
    "    \"s3://echodata25/results/echo-images/nova-pro/gen10/job_00/prompts.jsonl\",\n",
    "    \"s3://echodata25/results/echo-images/nova-pro/gen10/job_01/prompts.jsonl\",\n",
    "    \"s3://echodata25/results/echo-images/nova-pro/gen10/job_02/prompts.jsonl\",\n",
    "    \"s3://echodata25/results/echo-images/nova-pro/gen10/job_03/prompts.jsonl\",\n",
    "    \"s3://echodata25/results/echo-images/nova-pro/gen10/job_04/prompts.jsonl\",\n",
    "    \"s3://echodata25/results/echo-images/nova-pro/gen10/job_05/prompts.jsonl\",\n",
    "]\n",
    "\n",
    " # ------------------------------------------------------------\n",
    "# main loop\n",
    "# ------------------------------------------------------------\n",
    "frames = []\n",
    "outer = tqdm(uris, desc=\"all jobs\", unit=\"file\")   # overall progress\n",
    "\n",
    "for uri in outer:\n",
    "    job   = uri.split(\"/\")[-3]\n",
    "    total = row_count(uri)\n",
    "\n",
    "    rows = []\n",
    "    for rec in tqdm(stream_jsonl(uri),\n",
    "                    total=total,\n",
    "                    desc=job,\n",
    "                    unit=\"rows\",\n",
    "                    leave=True):      # keep each bar\n",
    "        rows.append(rec)\n",
    "\n",
    "    frames.append(pd.DataFrame.from_records(rows))\n",
    "    outer.update()                    # tick the master bar\n",
    "\n",
    "\n",
    "# final concatenation\n",
    "df_inputs = pd.concat(frames, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8716e417-9748-4e08-95c5-63f973e5e33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined shape: (266008, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Combined shape:\", df_inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1677daf0-3880-4146-9707-c9ae36c0e70c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abc3ac5398af4fbc9b96d47dd36ba95c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "all jobs:   0%|          | 0/1 [00:00<?, ?file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cb5acb2842d49c2a02575a917c67466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "gen11:   0%|          | 0/49025 [00:00<?, ?rows/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined shape: (49025, 2)\n"
     ]
    }
   ],
   "source": [
    "uris = [\n",
    " \"s3://echodata25/results/echo-images/nova-pro/gen11/job_00/prompts.jsonl\"\n",
    "]\n",
    "\n",
    "frames = []\n",
    "outer = tqdm(uris, desc=\"all jobs\", unit=\"file\")   # overall progress\n",
    "\n",
    "for uri in outer:\n",
    "    job   = uri.split(\"/\")[-3]\n",
    "    total = row_count(uri)\n",
    "\n",
    "    rows = []\n",
    "    for rec in tqdm(stream_jsonl(uri),\n",
    "                    total=total,\n",
    "                    desc=job,\n",
    "                    unit=\"rows\",\n",
    "                    leave=True):      # keep each bar\n",
    "        rows.append(rec)\n",
    "\n",
    "    frames.append(pd.DataFrame.from_records(rows))\n",
    "    outer.update()                    # tick the master bar\n",
    "\n",
    "\n",
    "# final concatenation\n",
    "gen11_inputs = pd.concat(frames, ignore_index=True)\n",
    "print(\"Combined shape:\", gen11_inputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa302637-2600-4700-8ff0-001024a32a99",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Parse Into Findings + Measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf9dc705-daea-4f01-8686-04da64a4d278",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inputs_parsed = parse_messages_to_df(df_inputs, col=\"messages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fbb5943-bad9-4cee-bdc6-45e0fbb48363",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen11_parsed = parse_messages_to_df(gen11_inputs, col=\"messages\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "449dfdc4-4e68-4940-977d-d62c47931e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_dict = pd.read_csv('hls_dict_v3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7989e1-827f-4db5-9156-b0ff155f230b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Drop Empty Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a168cccb-cd3f-4092-9e44-2c34b2536e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original rows: 266008\n",
      "tag-only rows  : 48,708\n",
      "“none provided” rows: 317\n",
      "remaining rows : 216983\n"
     ]
    }
   ],
   "source": [
    "def tag_only_str(s: str) -> bool:\n",
    "    \"\"\"\n",
    "    True  -> looks like a bare tag (no colon, no spaces)\n",
    "    False -> carries a value or is a free-text sentence\n",
    "    \"\"\"\n",
    "    return (\":\" not in s) and (\" \" not in s)\n",
    "\n",
    "def tag_only_row(lst) -> bool:\n",
    "    return isinstance(lst, list) and all(tag_only_str(x) for x in lst)\n",
    "\n",
    "def none_provided(lst):\n",
    "    return (isinstance(lst, list)                 and\n",
    "            len(lst) == 1                        and\n",
    "            lst[0].strip().lower() == \"none provided.\")\n",
    "\n",
    "print(f\"original rows: {len(df_inputs_parsed)}\")\n",
    "\n",
    "tag_only_mask   = df_inputs_parsed[\"study_findings\"].apply(tag_only_row)\n",
    "none_mask       = df_inputs_parsed[\"study_findings\"].apply(none_provided)\n",
    "\n",
    "# counts -----------------------------------------------------------------\n",
    "n_tag_only = tag_only_mask.sum()\n",
    "n_none     = none_mask.sum()\n",
    "\n",
    "print(f\"tag-only rows  : {n_tag_only:,}\")\n",
    "print(f'“none provided” rows: {n_none:,}')\n",
    "\n",
    "# separate DataFrames ----------------------------------------------------\n",
    "tag_only_df = df_inputs_parsed[tag_only_mask]\n",
    "none_df     = df_inputs_parsed[none_mask]\n",
    "\n",
    "# drop both categories from the main DataFrame ---------------------------\n",
    "df_inputs_parsed = df_inputs_parsed[~(tag_only_mask | none_mask)].reset_index(drop=True)\n",
    "print(\"remaining rows :\", len(df_inputs_parsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19b6f373-2f1f-4554-91b4-ce88a3dd4253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of dropped SIDs: 49,025\n",
      "Dropped SIDs that overlap with gen11_parsed: 100%\n"
     ]
    }
   ],
   "source": [
    "dropped_sids = set(tag_only_df[\"sid\"]).union(none_df[\"sid\"])\n",
    "print(f\"Total number of dropped SIDs: {len(dropped_sids):,}\")\n",
    "print(f\"Dropped SIDs that overlap with gen11_parsed: {(len(dropped_sids)/len(gen11_parsed))*100:.0f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94674c38-d9cf-4e55-a67c-0463d1321ba4",
   "metadata": {},
   "source": [
    "Now, dropped_sidshe JSONL outputs for only those prompt outputs whose SIDs overlap with the remaining `df_inputs_parsed`. The rest will be pulled from `gen11`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df17a0f4-fd0d-4012-a28d-51c3325fd355",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3959803-8b07-4a93-a982-dd14c6616128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8da9ba0cb4f4912bdca64ad44e26ec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "all jobs:   0%|          | 0/6 [00:00<?, ?file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0badaad15c7c4f34a16b54bc8f1476ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "job_00:   0%|          | 0/50000 [00:00<?, ?rows/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff67d935241245589df05ad2489223a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "job_01:   0%|          | 0/50000 [00:00<?, ?rows/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16d96d17557c46ed9481a18964cce61a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "job_02:   0%|          | 0/50000 [00:00<?, ?rows/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "293f76a3cc49492597c0ea6d07e0031d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "job_03:   0%|          | 0/50000 [00:00<?, ?rows/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ef0ac2372cd41deb1d7e07390dccb77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "job_04:   0%|          | 0/50000 [00:00<?, ?rows/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1601d2710e64e2cb47c40082f105ca4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "job_05:   0%|          | 0/16008 [00:00<?, ?rows/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined shape: (266008, 3)\n"
     ]
    }
   ],
   "source": [
    "uris = [\n",
    "    \"s3://echodata25/results/echo-images/nova-pro/gen10-outputs/job_00/koh3yhoh38cy/prompts.jsonl.out\",\n",
    "    \"s3://echodata25/results/echo-images/nova-pro/gen10-outputs/job_01/zhnxl9kb6alc/prompts.jsonl.out\",\n",
    "    \"s3://echodata25/results/echo-images/nova-pro/gen10-outputs/job_02/h74k0w4wqyuy/prompts.jsonl.out\",\n",
    "    \"s3://echodata25/results/echo-images/nova-pro/gen10-outputs/job_03/0db4t3ctdamr/prompts.jsonl.out\",\n",
    "    \"s3://echodata25/results/echo-images/nova-pro/gen10-outputs/job_04/9xztwg01glwe/prompts.jsonl.out\",\n",
    "    \"s3://echodata25/results/echo-images/nova-pro/gen10-outputs/job_05/9ynxch4xlfeq/prompts.jsonl.out\",\n",
    "]\n",
    "\n",
    " # ------------------------------------------------------------\n",
    "# main loop\n",
    "# ------------------------------------------------------------\n",
    "frames = []\n",
    "outer = tqdm(uris, desc=\"all jobs\", unit=\"file\")   # overall progress\n",
    "\n",
    "for uri in outer:\n",
    "    job   = uri.split(\"/\")[-3]\n",
    "    total = row_count(uri)\n",
    "\n",
    "    rows = []\n",
    "    for rec in tqdm(stream_jsonl(uri),\n",
    "                    total=total,\n",
    "                    desc=job,\n",
    "                    unit=\"rows\",\n",
    "                    leave=True):      # keep each bar\n",
    "        rows.append(rec)\n",
    "\n",
    "    frames.append(pd.DataFrame.from_records(rows))\n",
    "    outer.update()                    # tick the master bar\n",
    "\n",
    "\n",
    "# final concatenation\n",
    "df_all = pd.concat(frames, ignore_index=True)\n",
    "print(\"Combined shape:\", df_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "509e98ed-76ab-46f1-a357-e8d88a8a899d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bca0d631e0444328c1baa2e4cc87d0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "all jobs:   0%|          | 0/1 [00:00<?, ?file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1b9115e7abd440a8c19c9a1d78b6843",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "job_00:   0%|          | 0/49025 [00:00<?, ?rows/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "uris = [\n",
    " \"s3://echodata25/results/echo-images/nova-pro/gen11-outputs/job_00/lhmwnkih6ov0/prompts.jsonl.out\"\n",
    "]\n",
    "\n",
    "frames = []\n",
    "outer = tqdm(uris, desc=\"all jobs\", unit=\"file\")   # overall progress\n",
    "\n",
    "for uri in outer:\n",
    "    job   = uri.split(\"/\")[-3]\n",
    "    total = row_count(uri)\n",
    "\n",
    "    rows = []\n",
    "    for rec in tqdm(stream_jsonl(uri),\n",
    "                    total=total,\n",
    "                    desc=job,\n",
    "                    unit=\"rows\",\n",
    "                    leave=True):      # keep each bar\n",
    "        rows.append(rec)\n",
    "\n",
    "    frames.append(pd.DataFrame.from_records(rows))\n",
    "    outer.update()                    # tick the master bar\n",
    "\n",
    "\n",
    "# final concatenation\n",
    "gen11_outputs = pd.concat(frames, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15410e27-5b38-4190-acfe-c024c846e0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined shape: (49025, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Combined shape:\", gen11_outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b80118c-1362-42b8-a5d9-b2037c30e89e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Parse + Fix Conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68f8c722-42c8-4f6f-8579-60d6b101491d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process rows lazily; no extra dataframe copies\n",
    "ids, convs = zip(*map(parse_row, df_all.itertuples(index=False)))\n",
    "all_processed = pd.DataFrame({\"id\": ids, \"conversations\": convs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59c1e98c-ce7e-414d-be98-f0dd2b0c0e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(266008, 2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_processed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c48e810f-4bd9-4cec-8012-18d651b1f17b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f4bd99b6f48453e8f783fcc7f684ebc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/266008 [00:00<?, ?conv/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1213 rows truncated ➜ [366, 1501, 2620, 3930, 5297, 6029, 6868, 7208, 7825, 8270]\n"
     ]
    }
   ],
   "source": [
    "# ────────────────────────────────────────────────────────────────\n",
    "# 4 · clean whole column with a progress bar\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "all_processed_fixed        = all_processed.copy()                  # keep original safe\n",
    "good, bad = [], []\n",
    "\n",
    "for i, txt in tqdm(enumerate(all_processed_fixed[COL]), total=len(all_processed_fixed), unit=\"conv\"):\n",
    "    parsed = to_list(txt)\n",
    "    if parsed is None:\n",
    "        bad.append(i)\n",
    "    else:\n",
    "        good.append(parsed)\n",
    "\n",
    "print(f\"{len(bad)} rows truncated ➜ {bad[:10]}\")\n",
    "\n",
    "# drop unrecoverable rows, assign cleaned lists\n",
    "all_processed_fixed = all_processed_fixed.drop(index=bad).reset_index(drop=True)\n",
    "all_processed_fixed[COL] = good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a0c0065c-36c2-48c3-9d77-d3576235b8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process rows lazily; no extra dataframe copies\n",
    "ids, convs = zip(*map(parse_row, gen11_outputs.itertuples(index=False)))\n",
    "gen11_processed = pd.DataFrame({\"id\": ids, \"conversations\": convs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "055fd3e0-17f4-4ca6-8afa-df33436ceef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d44b980234b4fc6a0cfffbc2c594250",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49025 [00:00<?, ?conv/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1221 rows truncated ➜ [62, 96, 207, 244, 256, 276, 307, 342, 368, 423]\n"
     ]
    }
   ],
   "source": [
    "gen11_processed_fixed        = gen11_processed.copy()                  # keep original safe\n",
    "good, bad = [], []\n",
    "\n",
    "for i, txt in tqdm(enumerate(gen11_processed_fixed[COL]), total=len(gen11_processed_fixed), unit=\"conv\"):\n",
    "    parsed = to_list(txt)\n",
    "    if parsed is None:\n",
    "        bad.append(i)\n",
    "    else:\n",
    "        good.append(parsed)\n",
    "\n",
    "print(f\"{len(bad)} rows truncated ➜ {bad[:10]}\")\n",
    "\n",
    "# drop unrecoverable rows, assign cleaned lists\n",
    "gen11_processed_fixed = gen11_processed_fixed.drop(index=bad).reset_index(drop=True)\n",
    "gen11_processed_fixed[COL] = good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b3cc3e76-5fbb-470a-9a50-59bbe3999623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # raw_df (or new) → the dataframe that still has the raw strings\n",
    "# # bad           → list/array of bad-row indices\n",
    "\n",
    "# def peek_rows(df, indices, n=20, ctx=120):\n",
    "#     \"\"\"\n",
    "#     Print a context slice around the JSON error byte for the first `n` indices.\n",
    "#     \"\"\"\n",
    "#     import orjson\n",
    "#     for idx in indices[:n]:\n",
    "#         txt = df.at[idx, \"conversations\"]\n",
    "#         try:\n",
    "#             orjson.loads(txt)            # will raise\n",
    "#         except orjson.JSONDecodeError as e:\n",
    "#             pos = e.pos                  # byte offset where parsing broke\n",
    "#             frag = txt[max(0, pos-ctx): pos+ctx]\n",
    "#             print(f\"\\n── row {idx}  (byte {pos}) ──\\n{frag}\\n\")\n",
    "\n",
    "# peek_rows(raw_df, bad, n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d63cef-6ab8-498b-a462-57e2cd88eddc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Drop Invalid Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83eb437a-4d93-4f8d-8342-7bc312a98e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of all_processed_fixed before: 264795\n",
      "rows removed from other_df: 47,965\n",
      "remaining rows            : 216,830\n"
     ]
    }
   ],
   "source": [
    "before = len(all_processed_fixed)     \n",
    "print(f\"length of all_processed_fixed before: {len(all_processed_fixed)}\")\n",
    "\n",
    "all_processed_fixed = (all_processed_fixed\n",
    "            [~all_processed_fixed[\"id\"].astype(str).isin(dropped_sids)]\n",
    "            .reset_index(drop=True))\n",
    "\n",
    "after = len(all_processed_fixed)\n",
    "print(f\"rows removed from other_df: {before - after:,}\")\n",
    "print(f\"remaining rows            : {after:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43db5d9e-15d5-4343-a3f0-a2a26a384402",
   "metadata": {},
   "source": [
    "We don't want to do the same for `gen11_processed_fixed` because it contains the rows that were reprocessed by the LLM with the fixed inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "adddad2b-61e8-469e-a5bc-1638639b01f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDs in all_processed_fixed : 216,830\n",
      "IDs in gen11_processed_fixed: 47,804\n",
      "overlap count             : 0\n",
      "rows removed from all_processed_fixed: 0\n",
      "remaining rows                       : 216,830\n"
     ]
    }
   ],
   "source": [
    "col = \"id\"                 \n",
    "\n",
    "ids_all   = set(all_processed_fixed[col].astype(str))\n",
    "ids_gen11 = set(gen11_processed_fixed[col].astype(str))\n",
    "\n",
    "overlap   = ids_all & ids_gen11          # intersection\n",
    "\n",
    "print(f\"IDs in all_processed_fixed : {len(ids_all):,}\")\n",
    "print(f\"IDs in gen11_processed_fixed: {len(ids_gen11):,}\")\n",
    "print(f\"overlap count             : {len(overlap):,}\")\n",
    "\n",
    "before = len(all_processed_fixed)\n",
    "\n",
    "all_processed_fixed = (\n",
    "    all_processed_fixed[~all_processed_fixed[col].astype(str).isin(overlap)]\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "after = len(all_processed_fixed)\n",
    "print(f\"rows removed from all_processed_fixed: {before - after:,}\")\n",
    "print(f\"remaining rows                       : {after:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1610a0ba-7824-4d27-b0b4-26a3a6b28503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "master_conv shape: (264634, 2)\n"
     ]
    }
   ],
   "source": [
    "cols_all   = set(all_processed_fixed.columns)\n",
    "cols_gen11 = set(gen11_processed_fixed.columns)\n",
    "\n",
    "master_conv = pd.concat(\n",
    "    [all_processed_fixed, gen11_processed_fixed],\n",
    "    ignore_index=True,      # new 0-based index\n",
    "    sort=False              # keep column order, don’t alphabetize\n",
    ")\n",
    "\n",
    "print(\"master_conv shape:\", master_conv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33a96e3-80e7-4b27-99ab-48362a78a66c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Build Data Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "739dba56-f198-4fb4-a7c1-ee85d6c1042b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_master = pd.read_csv('hls_master_v3.csv') # now we import the master CSV to get the study directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4ebf48aa-f0f9-4a62-8212-fd19dc918e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a Series once → O(n) memory-light lookup table\n",
    "study_dir_map = (\n",
    "    hls_master\n",
    "    .set_index(\"DeidentifiedStudyID\")[\"study_dir\"]\n",
    "    .astype(str)          # make sure keys/vals are strings\n",
    ")\n",
    "\n",
    "# add column (vectorised; no join-copy)\n",
    "master_conv[\"data_source\"] = master_conv[\"id\"].map(study_dir_map) # we set the data_source to the study directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7719a8f7-d961-41e7-b069-55548152b619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     1.2.276.0.7230010.3.1.2.845494328.1.1703364833.18441940\n",
       "conversations    [{'from': 'human', 'value': '<image>\n",
       "Please provide an overview of cardiac structure and function you see here.'}, {'from': 'gpt', 'value': '<META_START>\n",
       "<C11> <C21> <C28> <C41> <C52> <C58> <C60> <C65> <C69> <C75>\n",
       "<META_END>\n",
       "\n",
       "The study shows a repaired Tetralogy of Fallot with a membranous ventricular septal defect and predominant left-to-right shunting. There is mild dilation of both atria and mild enlargement of the right ventricle. Global left ventricular function is normal, while right ventricular systolic function is mildly reduced.'}, {'from': 'human', 'value': 'Can you describe the appearance of the ventricular septal defect?'}, {'from': 'gpt', 'value': 'The ventricular septal defect appears as a small opening in the interventricular septum, demonstrated by color Doppler showing predominant left-to-right shunting with a peak gradient of 91 mmHg. The septal wall motion has a post-operative appearance, suggesting previous surgical intervention.'}, {'from': 'human', 'value': 'What are the characteristics of the tricuspid regurgitation observed?'}, {'from': 'gpt', 'value': 'The tricuspid regurgitation is moderate, with a visible jet extending into the right atrium. This is indicative of incomplete closure of the tricuspid valve during systole, leading to backflow of blood from the right ventricle to the right atrium.'}, {'from': 'human', 'value': 'Is there any evidence of aortic valve disease?'}, {'from': 'gpt', 'value': 'There is no evidence of aortic stenosis. However, mild aortic regurgitation is present, characterized by a small, localized jet seen on color Doppler, indicating slight backflow of blood from the aorta into the left ventricle during diastole.'}, {'from': 'human', 'value': 'What is the clinical significance of the mild pulmonic stenosis and severe pulmonic regurgitation?'}, {'from': 'gpt', 'value': 'The mild pulmonic stenosis may not significantly impact hemodynamics but should be monitored for progression. The severe pulmonic regurgitation, however, could lead to volume overload of the right ventricle, potentially contributing to the observed mild enlargement and reduced systolic function of the right ventricle.'}]\n",
       "data_source                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         echo-study\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_conv.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d430e1-4e07-4efa-b02f-e71535ed846d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# (Old) Get S3 Concatenated Video Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "00fe7e40-b057-4d30-bdc2-a9548ed25a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prerequisites\n",
    "# pip install boto3 tqdm orjson\n",
    "\n",
    "import random, boto3, orjson, re, pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# ---------- part 2 · pick one shuf*.mp4 per study --------------\n",
    "BUCKET   = \"echodata25\"\n",
    "ROOT     = \"results/echo-images/video-concat\"          # constant path prefix\n",
    "MATCHES  = (\"shuf1.mp4\", \"shuf2.mp4\")                  # wanted filenames\n",
    "MAX_WORKERS = 32                                       # tune for your net-bandwidth / vCPU\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "paginator = s3.get_paginator(\"list_objects_v2\")        # reused → keeps HTTP-pool alive\n",
    "\n",
    "def find_video(study_id: str, source_dir: str | float) -> str | None:\n",
    "    \"\"\"Return s3://…/shuf1|2.mp4 (random pick) or None.\"\"\"\n",
    "    if pd.isna(source_dir):\n",
    "        return None\n",
    "\n",
    "    prefix = f\"{ROOT}/{source_dir}/{study_id}/\"        # e.g. results/…/echo-study/<ID>/\n",
    "    try:\n",
    "        for page in paginator.paginate(Bucket=BUCKET, Prefix=prefix):\n",
    "            keys = [obj[\"Key\"] for obj in page.get(\"Contents\", ())\n",
    "                    if obj[\"Key\"].endswith(MATCHES)]\n",
    "            if keys:                                   # got one or more candidates\n",
    "                return f\"s3://{BUCKET}/{random.choice(keys)}\"\n",
    "    except s3.exceptions.NoSuchBucket:\n",
    "        pass                                           # bucket typo guard\n",
    "    return None\n",
    "\n",
    "# vectorised parallel lookup with progress bar\n",
    "ids   = out[\"id\"].values\n",
    "dirs  = out[\"data_source\"].values\n",
    "\n",
    "with ThreadPoolExecutor(MAX_WORKERS) as ex:\n",
    "    out[\"video\"] = list(\n",
    "        tqdm(ex.map(find_video, ids, dirs), total=len(out), unit=\"file\")\n",
    "    )\n",
    "\n",
    "# out now has columns: id · conversations · data_source · video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "01f05906-ae5b-47da-a847-76535338a3cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a29e609b53d4fb086dd9938663e47b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "videos:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampled videos : 20\n",
      "avg frames     : 3506.2\n",
      "avg fps        : 30.00\n",
      "avg duration s : 116.87\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Compute average frame-count, FPS, and duration over the first `N`\n",
    "videos listed in df[\"video\"] (each value is an s3://…/shuf*.mp4 URI).\n",
    "\n",
    "Dependencies  (install once):\n",
    "    pip install boto3 opencv-python-headless tqdm\n",
    "\"\"\"\n",
    "\n",
    "import os, tempfile, boto3, cv2, pandas as pd, numpy as np\n",
    "from urllib.parse import urlparse\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "N        = 20                             # ← how many videos to sample\n",
    "tmp_dir  = tempfile.mkdtemp()\n",
    "s3       = boto3.client(\"s3\")\n",
    "\n",
    "frames, fpss, durs = [], [], []\n",
    "\n",
    "def download(uri: str, dest_dir: str) -> str:\n",
    "    \"\"\"Download S3 object to `dest_dir`, return local path.\"\"\"\n",
    "    parsed = urlparse(uri)\n",
    "    bucket, key = parsed.netloc, parsed.path.lstrip(\"/\")\n",
    "    local = os.path.join(dest_dir, os.path.basename(key))\n",
    "    if os.path.exists(local):                      # cached\n",
    "        return local\n",
    "    s3.download_file(bucket, key, local)\n",
    "    return local\n",
    "\n",
    "for uri in tqdm(df[\"video\"].iloc[:N], total=N, desc=\"videos\"):\n",
    "    path = download(uri, tmp_dir)\n",
    "\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    if not cap.isOpened():                         # skip broken files\n",
    "        continue\n",
    "    f = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    r = cap.get(cv2.CAP_PROP_FPS) or np.nan\n",
    "    cap.release()\n",
    "\n",
    "    frames.append(f)\n",
    "    fpss.append(r)\n",
    "    durs.append(f / r if r else np.nan)\n",
    "\n",
    "# ── report ──────────────────────────────────────────────────────────────\n",
    "print(f\"sampled videos : {len(frames)}\")\n",
    "print(f\"avg frames     : {np.nanmean(frames):.1f}\")\n",
    "print(f\"avg fps        : {np.nanmean(fpss):.2f}\")\n",
    "print(f\"avg duration s : {np.nanmean(durs):.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affb925f-f95f-46e1-8b20-f34ac184a8ee",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Get Valid Study Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "36a25fb5-e2cf-428e-b0cf-126b5b4b286b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM total: 401.2 GB   free: 360.0 GB\n",
      "96 logical cores\n"
     ]
    }
   ],
   "source": [
    "# ---- Python (works in scripts / Jupyter) ----\n",
    "import os, psutil, multiprocessing\n",
    "\n",
    "ram = psutil.virtual_memory()\n",
    "print(f\"RAM total: {ram.total/1e9:.1f} GB   free: {ram.available/1e9:.1f} GB\")\n",
    "\n",
    "cpus_logical  = os.cpu_count()                 #\n",
    "\n",
    "import os, multiprocessing as mp\n",
    "n_logical  = os.cpu_count()        # includes hyper-threads\n",
    "n_physical = mp.cpu_count()        # same on Linux; fallback\n",
    "\n",
    "print(n_logical, \"logical cores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "73a54458-592f-4448-a5d8-9e9587bbaf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_llava = master_conv.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "75af51fb-86e6-41f9-9cb3-b68b1095db37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72ce51e4bc184a3385bdb2610965eb1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/264634 [00:00<?, ?study/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- directory statistics ---\n",
      " avg clips : 58.2\n",
      " min clips : 10\n",
      " max clips : 281\n",
      "studies with eligible dir : 263,964\n",
      "studies without dir       : 670\n"
     ]
    }
   ],
   "source": [
    "# prerequisites\n",
    "# pip install boto3 tqdm orjson\n",
    "\n",
    "import random, boto3, orjson, pandas as pd, re\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from collections import defaultdict\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "BUCKET       = \"echodata25\"\n",
    "MAX_WORKERS  = 96                                   # adjust to network / vCPU\n",
    "MIN_CLIPS    = 10                                   # threshold for “good” dir\n",
    "\n",
    "s3        = boto3.client(\"s3\")\n",
    "paginator = s3.get_paginator(\"list_objects_v2\")     # keeps HTTP pool alive\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# helper: find the first subdir with ≥10 mp4s and return (s3_dir, count)\n",
    "# ----------------------------------------------------------------------\n",
    "def select_dir(study_id: str, data_source: str | float):\n",
    "    \"\"\"Return (s3://bucket/.../subdir/, n_clips) or (None, 0).\"\"\"\n",
    "    if pd.isna(data_source):\n",
    "        return None, 0\n",
    "\n",
    "    root = f\"results/{data_source}/{study_id}/\"      # new root rule\n",
    "    try:\n",
    "        mp4_counts = defaultdict(int)                # subdir → clip count\n",
    "\n",
    "        # list every object under the study prefix\n",
    "        for page in paginator.paginate(Bucket=BUCKET, Prefix=root):\n",
    "            for obj in page.get(\"Contents\", ()):\n",
    "                key = obj[\"Key\"]\n",
    "                if not key.endswith(\".mp4\"):\n",
    "                    continue\n",
    "\n",
    "                # key looks like results/…/study_id/<subdir>/file.mp4\n",
    "                rel = key[len(root):]\n",
    "                if \"/\" not in rel:                   # mp4 directly under study root\n",
    "                    continue                         # skip (needs subdir)\n",
    "                subdir = rel.split(\"/\", 1)[0] + \"/\"  # keep trailing slash\n",
    "                mp4_counts[subdir] += 1\n",
    "\n",
    "        # pick the first subdir (sorted) with enough clips\n",
    "        for subdir in sorted(mp4_counts):\n",
    "            if mp4_counts[subdir] >= MIN_CLIPS:\n",
    "                s3_dir = f\"s3://{BUCKET}/{root}{subdir}\"\n",
    "                return s3_dir, mp4_counts[subdir]\n",
    "\n",
    "    except s3.exceptions.NoSuchBucket:\n",
    "        pass                                         # safety guard\n",
    "\n",
    "    return None, 0\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# vectorised parallel lookup with progress bar\n",
    "# `master_llava` must have columns: id  ·  data_source\n",
    "# ----------------------------------------------------------------------\n",
    "ids   = master_llava[\"id\"].values\n",
    "srcs  = master_llava[\"data_source\"].values\n",
    "\n",
    "with ThreadPoolExecutor(MAX_WORKERS) as ex:\n",
    "    results = list(tqdm(ex.map(select_dir, ids, srcs),\n",
    "                        total=len(master_llava), unit=\"study\"))\n",
    "\n",
    "# unpack tuples into two new columns\n",
    "master_llava[\"video\"]       = [r[0] for r in results]     # s3://…/subdir/\n",
    "master_llava[\"n_clips_dir\"] = [r[1] for r in results]     # integer count\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# stats\n",
    "# ----------------------------------------------------------------------\n",
    "has_video_mask = master_llava[\"video\"].notna()\n",
    "\n",
    "clip_counts = master_llava.loc[has_video_mask, \"n_clips_dir\"]\n",
    "\n",
    "print(\"\\n--- directory statistics ---\")\n",
    "if not clip_counts.empty:\n",
    "    print(f\" avg clips : {clip_counts.mean():.1f}\")\n",
    "    print(f\" min clips : {clip_counts.min()}\")\n",
    "    print(f\" max clips : {clip_counts.max()}\")\n",
    "else:\n",
    "    print(\"No directories selected.\")\n",
    "\n",
    "print(f\"studies with eligible dir : {has_video_mask.sum():,}\")\n",
    "print(f\"studies without dir       : {len(master_llava) - has_video_mask.sum():,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e9a258f7-e51e-46e6-9602-8e780e8338bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_llava.to_csv('master_llava.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bb0dd52b-0288-4018-9d69-509ee536fc75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264795"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f71ab8-c566-439a-b4e4-d13aca7b9402",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Combine w/ Salient Vids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "11f68416-04c4-4034-826b-ce284493d780",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "75daddac-d298-4905-bb60-6b8022438fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_llava = pd.read_csv('master_llava.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e1dfd0c5-d3b9-45e6-a80c-98f563ed6e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(264634, 6)\n",
      "Unnamed: 0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        0\n",
      "id                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          1.2.276.0.7230010.3.1.2.845494328.1.1703364833.18441940\n",
      "conversations    [{'from': 'human', 'value': '<image>\\nPlease provide an overview of cardiac structure and function you see here.'}, {'from': 'gpt', 'value': '<META_START>\\n<C11> <C21> <C28> <C41> <C52> <C58> <C60> <C65> <C69> <C75>\\n<META_END>\\n\\nThe study shows a repaired Tetralogy of Fallot with a membranous ventricular septal defect and predominant left-to-right shunting. There is mild dilation of both atria and mild enlargement of the right ventricle. Global left ventricular function is normal, while right ventricular systolic function is mildly reduced.'}, {'from': 'human', 'value': 'Can you describe the appearance of the ventricular septal defect?'}, {'from': 'gpt', 'value': 'The ventricular septal defect appears as a small opening in the interventricular septum, demonstrated by color Doppler showing predominant left-to-right shunting with a peak gradient of 91 mmHg. The septal wall motion has a post-operative appearance, suggesting previous surgical intervention.'}, {'from': 'human', 'value': 'What are the characteristics of the tricuspid regurgitation observed?'}, {'from': 'gpt', 'value': 'The tricuspid regurgitation is moderate, with a visible jet extending into the right atrium. This is indicative of incomplete closure of the tricuspid valve during systole, leading to backflow of blood from the right ventricle to the right atrium.'}, {'from': 'human', 'value': 'Is there any evidence of aortic valve disease?'}, {'from': 'gpt', 'value': 'There is no evidence of aortic stenosis. However, mild aortic regurgitation is present, characterized by a small, localized jet seen on color Doppler, indicating slight backflow of blood from the aorta into the left ventricle during diastole.'}, {'from': 'human', 'value': 'What is the clinical significance of the mild pulmonic stenosis and severe pulmonic regurgitation?'}, {'from': 'gpt', 'value': 'The mild pulmonic stenosis may not significantly impact hemodynamics but should be monitored for progression. The severe pulmonic regurgitation, however, could lead to volume overload of the right ventricle, potentially contributing to the observed mild enlargement and reduced systolic function of the right ventricle.'}]\n",
      "data_source                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              echo-study\n",
      "video                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.845494328.1.1703364833.18441940/1.2.276.0.7230010.3.1.3.845494328.1.1703364833.18441941/\n",
      "n_clips_dir                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      79\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(master_llava.shape)\n",
    "print(master_llava.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5f7fae4d-d1b4-4cad-be70-a525c13ee007",
   "metadata": {},
   "outputs": [],
   "source": [
    "es0_vids = pd.read_csv('es0_salient_vids.csv')\n",
    "es1_vids = pd.read_csv('es1_salient_vids.csv')\n",
    "es2_vids = pd.read_csv('es2_salient_vids.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d67146ad-4076-422f-b5d5-b9725c40959f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ast\n",
    "\n",
    "# count = (\n",
    "#     es1_vids['salient_videos']\n",
    "#         .map(lambda v: len(ast.literal_eval(v)) if isinstance(v, str) else len(v))\n",
    "#         .lt(10)\n",
    "#         .sum()\n",
    "# )\n",
    "# print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c03dc033-c0fc-45e6-acd7-0e385cab2cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(213773, 5)\n",
      "(25944, 5)\n",
      "(79526, 5)\n"
     ]
    }
   ],
   "source": [
    "print(es0_vids.shape)\n",
    "print(es1_vids.shape)\n",
    "print(es2_vids.shape)\n",
    "# print(es1_vids.iloc[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "46deae02-1904-4783-9532-c95286b7119f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "all_vids_list = [es0_vids, es1_vids, es2_vids]        # replace with your three dataframes\n",
    "all_vids = (\n",
    "    pd.concat(all_vids_list, ignore_index=True)\n",
    "      .drop(columns='Unnamed: 0', errors='ignore')         # remove index column\n",
    "      .drop_duplicates(subset='DeidentifiedStudyID')       # keep first occurrence\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8a87569a-6aac-4ae5-94e0-81e8c60666ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(319243, 4)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_vids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7c3a25fa-41b4-4706-be75-28a135f03b4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'id', 'conversations', 'data_source', 'video',\n",
       "       'n_clips_dir'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_llava.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1f1d197c-8cbd-4c4c-b7f7-79992576f10d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        0\n",
       "id                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          1.2.276.0.7230010.3.1.2.845494328.1.1703364833.18441940\n",
       "conversations    [{'from': 'human', 'value': '<image>\\nPlease provide an overview of cardiac structure and function you see here.'}, {'from': 'gpt', 'value': '<META_START>\\n<C11> <C21> <C28> <C41> <C52> <C58> <C60> <C65> <C69> <C75>\\n<META_END>\\n\\nThe study shows a repaired Tetralogy of Fallot with a membranous ventricular septal defect and predominant left-to-right shunting. There is mild dilation of both atria and mild enlargement of the right ventricle. Global left ventricular function is normal, while right ventricular systolic function is mildly reduced.'}, {'from': 'human', 'value': 'Can you describe the appearance of the ventricular septal defect?'}, {'from': 'gpt', 'value': 'The ventricular septal defect appears as a small opening in the interventricular septum, demonstrated by color Doppler showing predominant left-to-right shunting with a peak gradient of 91 mmHg. The septal wall motion has a post-operative appearance, suggesting previous surgical intervention.'}, {'from': 'human', 'value': 'What are the characteristics of the tricuspid regurgitation observed?'}, {'from': 'gpt', 'value': 'The tricuspid regurgitation is moderate, with a visible jet extending into the right atrium. This is indicative of incomplete closure of the tricuspid valve during systole, leading to backflow of blood from the right ventricle to the right atrium.'}, {'from': 'human', 'value': 'Is there any evidence of aortic valve disease?'}, {'from': 'gpt', 'value': 'There is no evidence of aortic stenosis. However, mild aortic regurgitation is present, characterized by a small, localized jet seen on color Doppler, indicating slight backflow of blood from the aorta into the left ventricle during diastole.'}, {'from': 'human', 'value': 'What is the clinical significance of the mild pulmonic stenosis and severe pulmonic regurgitation?'}, {'from': 'gpt', 'value': 'The mild pulmonic stenosis may not significantly impact hemodynamics but should be monitored for progression. The severe pulmonic regurgitation, however, could lead to volume overload of the right ventricle, potentially contributing to the observed mild enlargement and reduced systolic function of the right ventricle.'}]\n",
       "data_source                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              echo-study\n",
       "video                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.845494328.1.1703364833.18441940/1.2.276.0.7230010.3.1.3.845494328.1.1703364833.18441941/\n",
       "n_clips_dir                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      79\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_llava.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c5febe7f-ca6e-4c95-93d4-28b1e03f9b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(264634, 6)\n"
     ]
    }
   ],
   "source": [
    "# 2. (optional) ensure master_llava has unique IDs\n",
    "master_llava = master_llava.drop_duplicates('id')\n",
    "print(master_llava.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5f668125-b4ec-4800-8da7-a10bfbcf9316",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_llava_vids = (\n",
    "    all_vids\n",
    "        .merge(master_llava[['id', 'conversations']], left_on='DeidentifiedStudyID', right_on='id', how='inner')\n",
    "        .drop(columns='DeidentifiedStudyID')        # keep 'id', discard old column\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "423ae06a-bf35-4326-8bdf-90a3a852d5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_llava_vids.to_csv('master_llava_vids.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fed0c0f-67e5-4354-a52c-f14fd69393d4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e7817360-1761-434d-9fd2-e866fdd0f92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# master_llava_vids = pd.read_csv('master_llava_vids.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "309e7745-233b-427a-8143-95c04ce235ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from sagemaker.pytorch import PyTorch\n",
    "import sagemaker, boto3\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# 👇  we’re already inside the BIMBA folder, so just use cwd()\n",
    "SRC_DIR = Path.cwd()                         # /home/.../user-default-efs/BIMBA\n",
    "REQ_FILE = SRC_DIR / \"BIMBA-LLaVA-NeXT\" / \"requirements.txt\"\n",
    "IMAGE_URI = \"495467399120.dkr.ecr.us-west-2.amazonaws.com/bimba-train:latest\"\n",
    "\n",
    "estimator = PyTorch(\n",
    "    image_uri        = IMAGE_URI,\n",
    "    entry_point      = \"train_entrypoint.py\",   # file is right here\n",
    "    source_dir       = str(SRC_DIR),            # <-- fixed path\n",
    "    dependencies     = [str(REQ_FILE)],\n",
    "    role             = role,\n",
    "    instance_type    = \"ml.p4d.24xlarge\", # ml.p4d.24xlarge, ml.p4de.24xlarge, ml.p5.48xlarge\n",
    "    instance_count   = 1,\n",
    "    framework_version = \"2.1\",\n",
    "    py_version       = \"py310\",\n",
    "    base_job_name    = \"bimba-train\",\n",
    "    disable_profiler = True,\n",
    "    environment={\"ECHO_DEBUG\": \"1\"}, \n",
    ")\n",
    "\n",
    "estimator.fit(\n",
    "    inputs = {\n",
    "        \"training\": \"s3://echodata25/BIMBA-LLaVA-NeXT/mlv_1.jsonl\"\n",
    "    },\n",
    "    wait   = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f7015ff4-be95-447e-a755-c1dffcd66cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── 1. measurement-tag dictionary ────────────────────────────────────────────\n",
    "meas_tag_map = {\n",
    "    \"<N0>\":  \"<aortic_valve_peak_velocity>\",\n",
    "    \"<N1>\":  \"<aortic_valve_mean_gradient>\",\n",
    "    \"<N2>\":  \"<aortic_valve_effective_orifice_area>\",\n",
    "    \"<N3>\":  \"<aortic_valve_dimensionless_index>\",\n",
    "    \"<N4>\":  \"<left_ventricular_ejection_fraction>\",\n",
    "    \"<N5>\":  \"<left_ventricular_end_diastolic_volume_index>\",\n",
    "    \"<N6>\":  \"<left_ventricular_end_systolic_volume_index>\",\n",
    "    \"<N7>\":  \"<left_ventricular_mass_index>\",\n",
    "    \"<N8>\":  \"<left_ventricular_dpdt>\",\n",
    "    \"<N9>\":  \"<left_ventricular_outflow_tract_velocity_time_integral>\",\n",
    "    \"<N10>\": \"<left_ventricular_outflow_tract_peak_gradient>\",\n",
    "    \"<N11>\": \"<mitral_inflow_deceleration_time>\",\n",
    "    \"<N12>\": \"<mitral_e_a_ratio>\",\n",
    "    \"<N13>\": \"<mitral_e_e_prime_ratio>\",\n",
    "    \"<N14>\": \"<right_ventricular_systolic_pressure>\",\n",
    "    \"<N15>\": \"<right_ventricular_fractional_area_change>\",\n",
    "    \"<N16>\": \"<tricuspid_annular_plane_systolic_excursion>\",\n",
    "    \"<N17>\": \"<left_atrial_volume_index>\",\n",
    "    \"<N18>\": \"<aortic_root_diameter>\",\n",
    "    \"<N19>\": \"<ascending_aorta_diameter>\",\n",
    "}\n",
    "\n",
    "# ── 2. replacement helper (re-usable with the condition tags) ───────────────\n",
    "import re, ast\n",
    "\n",
    "def to_py(x):\n",
    "    if isinstance(x, list): return x\n",
    "    if isinstance(x, str) and x.lstrip().startswith(\"[\"):\n",
    "        try: return ast.literal_eval(x)\n",
    "        except Exception: pass\n",
    "    return x                       # NaN / other types\n",
    "\n",
    "def make_replacer(tag_map):\n",
    "    pattern = re.compile(\"|\".join(map(re.escape, tag_map)))\n",
    "    return lambda s: pattern.sub(lambda m: tag_map[m.group()], s)\n",
    "\n",
    "meas_repl = make_replacer(meas_tag_map)\n",
    "\n",
    "def expand_meas_tags(conv_list):\n",
    "    if not isinstance(conv_list, list):        # NaN etc.\n",
    "        return conv_list\n",
    "    out = []\n",
    "    for msg in conv_list:\n",
    "        if isinstance(msg, dict) and \"value\" in msg and isinstance(msg[\"value\"], str):\n",
    "            msg = msg.copy()\n",
    "            msg[\"value\"] = meas_repl(msg[\"value\"])\n",
    "        out.append(msg)\n",
    "    return out\n",
    "\n",
    "# ── 3. apply to the dataframe column 'conversations' ────────────────────────\n",
    "master_llava_vids[\"conversations\"] = (\n",
    "    master_llava_vids[\"conversations\"]\n",
    "        .map(to_py)\n",
    "        .map(expand_meas_tags)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6b9aa70c-a049-4da1-a5ae-83d169d67aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data_source                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       echo-study\n",
       "salient_videos    ['s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.811753780.1.1703121096.8327763.mp4', 's3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.845494328.1.1703121183.13461417.mp4', 's3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.1714578744.1.1703121416.8082906.mp4', 's3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.1714512485.1.1703121105.10482320.mp4', 's3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.1714512485.1.1703121077.10481855.mp4', 's3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.845494328.1.1703121022.13458474.mp4', 's3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.1714512485.1.1703121013.10480622.mp4', 's3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.845494328.1.1703121426.13465531.mp4', 's3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.811753780.1.1703121747.8338151.mp4', 's3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.811753780.1.1703121548.8335003.mp4', 's3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.1714578744.1.1703121235.8080103.mp4', 's3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.845494328.1.1703121336.13464060.mp4', 's3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.845494328.1.1703120993.13457982.mp4', 's3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.811753780.1.1703121567.8335303.mp4', 's3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.811753780.1.1703121519.8334490.mp4', 's3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.1714512485.1.1703121435.10488280.mp4', 's3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.845494328.1.1703121594.13468473.mp4', 's3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.811753780.1.1703121211.8329496.mp4', 's3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.1714578744.1.1703121202.8079592.mp4', 's3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.811753780.1.1703121088.8327639.mp4', 's3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.859333938.1.1703121537.8131940.mp4', 's3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.1714512485.1.1703121263.10485213.mp4', 's3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.845494328.1.1703121703.13470399.mp4', 's3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.1714578744.1.1703121490.8084014.mp4', 's3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.845494328.1.1703121480.13466479.mp4', 's3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.845494328.1.1703121558.13467859.mp4', 's3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.811753780.1.1703121460.8333516.mp4', 's3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.1714578744.1.1703121529.8084662.mp4', 's3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.859333938.1.1703121140.8125595.mp4', 's3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.1714578744.1.1703121684.8087056.mp4', 's3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.845494328.1.1703121171.13461196.mp4', 's3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.859333938.1.1703121192.8126466.mp4']\n",
       "salient_views                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ['psax-av', 'plax', 'a4c', 'psax-av', 'plax', 'plax', 'plax', 'a5c', 'plax', 'a3c', 'a4c', 'a4c', 'plax', 'a2c', 'a2c', 'a5c', 'plax', 'a4c', 'psax-ap', 'psax-av', 'a3c', 'a4c', 'psax-mv', 'plax', 'a2c', 'a3c', 'a2c', 'a2c', 'plax', 'psax-mv', 'psax-mv', 'psax-pm']\n",
       "id                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112\n",
       "conversations                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                [{'from': 'human', 'value': '<image>\n",
       "Give me a brief first-pass impression of this echocardiogram.'}, {'from': 'gpt', 'value': '<META_START>\n",
       "<aortic_stenosis_none> <ivc_respiratory_collapse_lt_50> <left_atrial_size_mild> <left_ventricular_cavity_size_normal> <pericardial_effusion_none> <right_ventricular_systolic_pressure> 111.0 <right_ventricular_fractional_area_change> 14.0 <left_atrial_volume_index> 94.0 <aortic_valve_mean_gradient> 14.0 <aortic_valve_effective_orifice_area> 8.0 <left_ventricular_ejection_fraction> 62.0 <left_ventricular_end_systolic_volume_index> 69.0 <left_ventricular_mass_index> 103.0\n",
       "<META_END>\n",
       "\n",
       "The echocardiogram shows normal left ventricular systolic function with an ejection fraction of 62%, mild left atrial dilation, and normal right ventricular function. There are no significant valvular abnormalities noted.'}, {'from': 'human', 'value': 'Can you describe the left ventricular function in more detail?'}, {'from': 'gpt', 'value': 'The left ventricle demonstrates normal systolic function with an ejection fraction of 62%. The ventricular walls contract vigorously and symmetrically, with good inward movement during systole. The chamber size appears normal with clearly visible endocardial borders and appropriate wall thickness.'}, {'from': 'human', 'value': 'What about the left atrium?'}, {'from': 'gpt', 'value': 'The left atrium is mildly dilated, as indicated by the left atrial volume index of 94.0 ml. This dilation is visually apparent as the left atrial chamber appears larger than adjacent structures, though it does not occupy an excessive portion of the cardiac silhouette.'}, {'from': 'human', 'value': 'Are there any abnormalities in the valves?'}, {'from': 'gpt', 'value': 'There are no significant valvular abnormalities noted. The aortic valve is tricuspid and appears normal in structure and function. There is trace tricuspid regurgitation and trivial mitral regurgitation present, but these are not hemodynamically significant. The pulmonic valve also appears normal.'}, {'from': 'human', 'value': 'Is there any evidence of right ventricular dysfunction?'}, {'from': 'gpt', 'value': 'No, there is no evidence of right ventricular dysfunction. The right ventricular cavity size is normal, and the global systolic function is within normal limits, as indicated by the fractional area change of 14.0%. The right ventricular function appears visually normal with appropriate contractility and wall motion.'}, {'from': 'human', 'value': 'What are the clinical implications of these findings?'}, {'from': 'gpt', 'value': 'The normal left ventricular function and absence of significant valvular abnormalities suggest a stable hemodynamic state. The mild left atrial dilation may warrant monitoring for potential atrial fibrillation or other atrial pathologies. Overall, the findings do not indicate an urgent need for intervention but should be monitored during follow-up evaluations.'}]\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_llava_vids.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "14cd0829-cbb2-46ff-9a05-8c34cb0cd29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "# ── 1. helper: pull every <…> token from a string ───────────────────────────\n",
    "_tag_re = re.compile(r\"<[^>]+>\")          # matches <anything_inside_angle_brackets>\n",
    "\n",
    "def tags_in_text(t: str):\n",
    "    return _tag_re.findall(t)             # returns list of tags (may be empty)\n",
    "\n",
    "\n",
    "# ── 2. walk through the dataframe, accumulate counts ────────────────────────\n",
    "counter = Counter()\n",
    "\n",
    "for conv in master_llava_vids[\"conversations\"]:\n",
    "    if not isinstance(conv, list):\n",
    "        continue                          # skip NaN / malformed rows\n",
    "    for msg in conv:\n",
    "        if isinstance(msg, dict) and \"value\" in msg and isinstance(msg[\"value\"], str):\n",
    "            counter.update(tags_in_text(msg[\"value\"]))\n",
    "\n",
    "# ── 3. convert to a tidy pandas Series (optional) ───────────────────────────\n",
    "tag_counts = pd.Series(counter).sort_values(ascending=False)\n",
    "\n",
    "# tag_counts now holds a per-tag frequency table, e.g.:\n",
    "# <left_ventricular_ejection_fraction>      812\n",
    "# <tricuspid_regurgitation_mild>            647\n",
    "# …\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "71380b1f-49f0-4f16-9cbc-0f572e05e27d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(264186, 5)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_llava_vids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6d5120aa-6b1d-40ba-b592-98d4abcb3e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "# ensure every cell is a list object\n",
    "master_llava_vids['salient_videos'] = master_llava_vids['salient_videos'].apply(\n",
    "    lambda x: x if isinstance(x, list) else ast.literal_eval(x)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e281e6ef-8092-4f8f-a3ea-72c030be4506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only rows whose list is non-empty\n",
    "master_llava_vids = (\n",
    "    master_llava_vids[master_llava_vids['salient_videos'].apply(len) >= 1]\n",
    "      .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6a1fa3f5-ba04-4d2c-a2c2-1f1caf1f890a",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_llava_vids.to_csv('master_llava_vids_retagged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6598145d-d8fb-415f-92a3-fae11ba7e8ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(252030, 5)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_llava_vids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b24dbeba-8ce0-48c9-b151-6b704f41c06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252030\n"
     ]
    }
   ],
   "source": [
    "# rows where the list has fewer than 10 elements\n",
    "n_short = (master_llava_vids['salient_videos'].apply(len) < 33).sum()\n",
    "print(n_short)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf99bb20-b6e3-4594-9fdc-8c827f484239",
   "metadata": {},
   "source": [
    "# Drop Rows Not Yet Processed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64898b9-9dd1-4068-90c6-daa231a44a17",
   "metadata": {},
   "source": [
    "1. ~Also drop all of Syngo (54K rows) until it is reprocessed (findings column)~\n",
    "2. ~Change all C63 to C61 (RA dilation)~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac412f87-04f5-485c-aa54-5337a118055b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4eb40bd6-746d-41de-8256-63fa182390d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3, json, pandas as pd, itertools\n",
    "from tqdm.notebook import tqdm            # Jupyter/HTML bar\n",
    "\n",
    "s3 = boto3.client(\"s3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39e9aee6-0722-4eab-9726-4eaa6f4ea4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_llava_vids = pd.read_csv('master_llava_vids_retagged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "43e5083f-b9c6-4140-bca3-d9aaf21bcff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick sanity-check\n",
    "df_ok = master_llava_vids\n",
    "try:\n",
    "    df_ok[\"conversations\"] = df_ok[\"conversations\"].apply(to_list)\n",
    "except Exception as e:\n",
    "    print(\"❌  at least one bad row in 'conversations':\", e)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9022fe2a-e98d-4cd8-8c61-556881df961e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, ast, pandas as pd\n",
    "\n",
    "def to_list(x):\n",
    "    \"\"\"Make sure each cell is a list of dicts.\"\"\"\n",
    "    if isinstance(x, list):\n",
    "        return x                    # already good\n",
    "    if isinstance(x, str):\n",
    "        # try proper JSON first (double-quoted)\n",
    "        try:\n",
    "            return json.loads(x)\n",
    "        except json.JSONDecodeError:\n",
    "            # fall back to Python repr (single-quoted)\n",
    "            return ast.literal_eval(x)\n",
    "    raise ValueError(\"unexpected type in conversations column\")\n",
    "\n",
    "df_ok[\"conversations\"] = df_ok[\"conversations\"].apply(to_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "69b0c29b-81d6-436a-a164-c2e8858283c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows in df_ok: 252030\n"
     ]
    }
   ],
   "source": [
    "print(\"rows in df_ok:\", len(df_ok))\n",
    "# print(df_ok.head(3))\n",
    "assert len(df_ok) > 0, \"⚠️  DataFrame is empty!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eee34e4c-3cce-4bd4-a0c9-d519e693dbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_py(obj):\n",
    "    \"\"\"Convert JSON / repr string to real Python object.\"\"\"\n",
    "    if isinstance(obj, list):\n",
    "        return obj\n",
    "    if isinstance(obj, str):\n",
    "        try:\n",
    "            return json.loads(obj)          # valid JSON list?\n",
    "        except json.JSONDecodeError:\n",
    "            return ast.literal_eval(obj)    # Python-repr list\n",
    "    return obj                              # fall through\n",
    "\n",
    "df_ok[\"conversations\"]   = df_ok[\"conversations\"].apply(to_py)\n",
    "df_ok[\"salient_videos\"]  = df_ok[\"salient_videos\"].apply(to_py)\n",
    "df_ok[\"salient_views\"]   = df_ok[\"salient_views\"].apply(to_py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d85b355d-0b66-40ed-81ca-3c8d6e28c7d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "588d16506c5743549ff7dd26c912ce47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "writing:   0%|          | 0/252030 [00:00<?, ?rows/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ wrote BIMBA-LLaVA-NeXT/mlv_1.jsonl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "OUT = \"BIMBA-LLaVA-NeXT/mlv_1.jsonl\"\n",
    "\n",
    "with open(OUT, \"w\", encoding=\"utf-8\") as f:\n",
    "    for _, row in tqdm(df_ok.iterrows(), total=len(df_ok),\n",
    "                       desc=\"writing\", unit=\"rows\"):\n",
    "        rec = {\n",
    "            \"id\":          str(row[\"id\"]),\n",
    "            \"salient_videos\":       row[\"salient_videos\"],\n",
    "            \"salient_views\":       row[\"salient_views\"],\n",
    "            \"conversations\": row[\"conversations\"],   # already a list of dicts\n",
    "        }\n",
    "\n",
    "        f.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"✅ wrote {OUT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f9270a41-d3fc-43b7-9971-6fb12b171e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👀 final jsonl rows: 252030\n"
     ]
    }
   ],
   "source": [
    "# after the cleaning loop, before the S3 upload\n",
    "num_lines = sum(1 for _ in open(OUT))\n",
    "print(\"👀 final jsonl rows:\", num_lines)\n",
    "# print(\"first two rows:\\n\", open(OUT).read().splitlines()[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0787be12-3e26-4cff-b230-0a1c115bb3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import boto3\n",
    "# s3 = boto3.client(\"s3\")\n",
    "\n",
    "# local_file  = OUT\n",
    "# bucket      = \"echodata25\"\n",
    "# s3_key      = \"data/mlv_1.jsonl\"\n",
    "\n",
    "# s3.upload_file(local_file, bucket, s3_key)\n",
    "# print(f\"✔️ uploaded to s3://{bucket}/{s3_key}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "47678099-06e4-4e02-8438-b01782c431ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf9a8a5-24a9-4cbc-83d3-30f24970c60b",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "354f2542-561a-4fe7-84d6-b15eccc3eea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e09ddfee33db4bf4ab10911e66855f56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "filtering: 0line [00:00, ?line/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary: Counter({'missing value': 4})\n",
      "kept 252,026  |  dropped 4\n",
      "local file saved → BIMBA-LLaVA-NeXT/mlv_1_clean.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json, collections, pathlib, gzip, boto3, shutil, os\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# ─── paths ───────────────────────────────────────────────────────────\n",
    "SRC = pathlib.Path(\"BIMBA-LLaVA-NeXT/mlv_1.jsonl\")\n",
    "DST = SRC.with_stem(SRC.stem + \"_clean\")     # mlv_1_clean.jsonl\n",
    "S3_BUCKET  = \"echodata25\"\n",
    "S3_KEY     = \"BIMBA-LLaVA-NeXT/mlv_1.jsonl\"\n",
    "\n",
    "problems = collections.Counter()\n",
    "kept = dropped = 0\n",
    "\n",
    "# helper for .gz / plain text\n",
    "def _opener(p: pathlib.Path, mode: str):\n",
    "    if p.suffix == \".gz\":\n",
    "        return gzip.open(p, mode + \"t\", encoding=\"utf-8\")\n",
    "    return p.open(mode, encoding=\"utf-8\")\n",
    "\n",
    "# ─── filter loop ─────────────────────────────────────────────────────\n",
    "with _opener(SRC, \"r\") as fin, DST.open(\"w\", encoding=\"utf-8\") as fout, \\\n",
    "     tqdm(desc=\"filtering\", unit=\"line\") as bar:\n",
    "    for line in fin:\n",
    "        bar.update()\n",
    "        try:\n",
    "            row = json.loads(line)\n",
    "        except json.JSONDecodeError:\n",
    "            problems[\"invalid json\"] += 1\n",
    "            dropped += 1\n",
    "            continue\n",
    "\n",
    "        for t in row.get(\"conversations\", []):\n",
    "            if \"value\" not in t:\n",
    "                problems[\"missing value\"] += 1\n",
    "                dropped += 1\n",
    "                break\n",
    "            if not isinstance(t[\"value\"], str):\n",
    "                problems[\"not a string\"] += 1\n",
    "                dropped += 1\n",
    "                break\n",
    "        else:                       # ← good row\n",
    "            fout.write(line)\n",
    "            kept += 1\n",
    "\n",
    "print(\"summary:\", problems or \"all good\")\n",
    "print(f\"kept {kept:,}  |  dropped {dropped:,}\")\n",
    "print(f\"local file saved → {DST}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1fb47bd0-88e0-4e13-9743-94d43d76870c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👀 final jsonl rows: 252026\n",
      "first two rows:\n",
      " ['{\"id\": \"1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112\", \"salient_videos\": \"[\\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.811753780.1.1703121096.8327763.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.845494328.1.1703121183.13461417.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.1714578744.1.1703121416.8082906.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.1714512485.1.1703121105.10482320.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.1714512485.1.1703121077.10481855.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.845494328.1.1703121022.13458474.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.1714512485.1.1703121013.10480622.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.845494328.1.1703121426.13465531.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.811753780.1.1703121747.8338151.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.811753780.1.1703121548.8335003.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.1714578744.1.1703121235.8080103.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.845494328.1.1703121336.13464060.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.845494328.1.1703120993.13457982.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.811753780.1.1703121567.8335303.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.811753780.1.1703121519.8334490.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.1714512485.1.1703121435.10488280.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.845494328.1.1703121594.13468473.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.811753780.1.1703121211.8329496.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.1714578744.1.1703121202.8079592.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.811753780.1.1703121088.8327639.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.859333938.1.1703121537.8131940.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.1714512485.1.1703121263.10485213.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.845494328.1.1703121703.13470399.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.1714578744.1.1703121490.8084014.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.845494328.1.1703121480.13466479.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.845494328.1.1703121558.13467859.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.811753780.1.1703121460.8333516.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.1714578744.1.1703121529.8084662.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.859333938.1.1703121140.8125595.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.1714578744.1.1703121684.8087056.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.845494328.1.1703121171.13461196.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120985.10480112/1.2.276.0.7230010.3.1.3.1714512485.1.1703120985.10480113/1.2.276.0.7230010.3.1.4.859333938.1.1703121192.8126466.mp4\\']\", \"salient_views\": \"[\\'psax-av\\', \\'plax\\', \\'a4c\\', \\'psax-av\\', \\'plax\\', \\'plax\\', \\'plax\\', \\'a5c\\', \\'plax\\', \\'a3c\\', \\'a4c\\', \\'a4c\\', \\'plax\\', \\'a2c\\', \\'a2c\\', \\'a5c\\', \\'plax\\', \\'a4c\\', \\'psax-ap\\', \\'psax-av\\', \\'a3c\\', \\'a4c\\', \\'psax-mv\\', \\'plax\\', \\'a2c\\', \\'a3c\\', \\'a2c\\', \\'a2c\\', \\'plax\\', \\'psax-mv\\', \\'psax-mv\\', \\'psax-pm\\']\", \"conversations\": [{\"from\": \"human\", \"value\": \"<image>\\\\nGive me a brief first-pass impression of this echocardiogram.\"}, {\"from\": \"gpt\", \"value\": \"<META_START>\\\\n<aortic_stenosis_none> <ivc_respiratory_collapse_lt_50> <left_atrial_size_mild> <left_ventricular_cavity_size_normal> <pericardial_effusion_none> <right_ventricular_systolic_pressure> 111.0 <right_ventricular_fractional_area_change> 14.0 <left_atrial_volume_index> 94.0 <aortic_valve_mean_gradient> 14.0 <aortic_valve_effective_orifice_area> 8.0 <left_ventricular_ejection_fraction> 62.0 <left_ventricular_end_systolic_volume_index> 69.0 <left_ventricular_mass_index> 103.0\\\\n<META_END>\\\\n\\\\nThe echocardiogram shows normal left ventricular systolic function with an ejection fraction of 62%, mild left atrial dilation, and normal right ventricular function. There are no significant valvular abnormalities noted.\"}, {\"from\": \"human\", \"value\": \"Can you describe the left ventricular function in more detail?\"}, {\"from\": \"gpt\", \"value\": \"The left ventricle demonstrates normal systolic function with an ejection fraction of 62%. The ventricular walls contract vigorously and symmetrically, with good inward movement during systole. The chamber size appears normal with clearly visible endocardial borders and appropriate wall thickness.\"}, {\"from\": \"human\", \"value\": \"What about the left atrium?\"}, {\"from\": \"gpt\", \"value\": \"The left atrium is mildly dilated, as indicated by the left atrial volume index of 94.0 ml. This dilation is visually apparent as the left atrial chamber appears larger than adjacent structures, though it does not occupy an excessive portion of the cardiac silhouette.\"}, {\"from\": \"human\", \"value\": \"Are there any abnormalities in the valves?\"}, {\"from\": \"gpt\", \"value\": \"There are no significant valvular abnormalities noted. The aortic valve is tricuspid and appears normal in structure and function. There is trace tricuspid regurgitation and trivial mitral regurgitation present, but these are not hemodynamically significant. The pulmonic valve also appears normal.\"}, {\"from\": \"human\", \"value\": \"Is there any evidence of right ventricular dysfunction?\"}, {\"from\": \"gpt\", \"value\": \"No, there is no evidence of right ventricular dysfunction. The right ventricular cavity size is normal, and the global systolic function is within normal limits, as indicated by the fractional area change of 14.0%. The right ventricular function appears visually normal with appropriate contractility and wall motion.\"}, {\"from\": \"human\", \"value\": \"What are the clinical implications of these findings?\"}, {\"from\": \"gpt\", \"value\": \"The normal left ventricular function and absence of significant valvular abnormalities suggest a stable hemodynamic state. The mild left atrial dilation may warrant monitoring for potential atrial fibrillation or other atrial pathologies. Overall, the findings do not indicate an urgent need for intervention but should be monitored during follow-up evaluations.\"}]}', '{\"id\": \"1.2.276.0.7230010.3.1.2.1714512485.1.1703120965.10479746\", \"salient_videos\": \"[\\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120965.10479746/1.2.276.0.7230010.3.1.3.1714512485.1.1703121090.10482068/1.2.276.0.7230010.3.1.4.1714578744.1.1703122323.8096900.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120965.10479746/1.2.276.0.7230010.3.1.3.1714512485.1.1703121090.10482068/1.2.276.0.7230010.3.1.4.1714578744.1.1703122742.8103046.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120965.10479746/1.2.276.0.7230010.3.1.3.1714512485.1.1703121090.10482068/1.2.276.0.7230010.3.1.4.811753780.1.1703122213.8345676.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120965.10479746/1.2.276.0.7230010.3.1.3.1714512485.1.1703121090.10482068/1.2.276.0.7230010.3.1.4.811753780.1.1703121797.8338991.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120965.10479746/1.2.276.0.7230010.3.1.3.1714512485.1.1703121090.10482068/1.2.276.0.7230010.3.1.4.1714578744.1.1703121204.8079629.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120965.10479746/1.2.276.0.7230010.3.1.3.1714512485.1.1703121090.10482068/1.2.276.0.7230010.3.1.4.1714578744.1.1703122111.8093637.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120965.10479746/1.2.276.0.7230010.3.1.3.1714512485.1.1703121090.10482068/1.2.276.0.7230010.3.1.4.859333938.1.1703122762.8150637.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120965.10479746/1.2.276.0.7230010.3.1.3.1714512485.1.1703121090.10482068/1.2.276.0.7230010.3.1.4.811753780.1.1703122000.8342199.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120965.10479746/1.2.276.0.7230010.3.1.3.1714512485.1.1703121090.10482068/1.2.276.0.7230010.3.1.4.811753780.1.1703122929.8356260.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120965.10479746/1.2.276.0.7230010.3.1.3.1714512485.1.1703121090.10482068/1.2.276.0.7230010.3.1.4.1714512485.1.1703123232.10520526.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120965.10479746/1.2.276.0.7230010.3.1.3.1714512485.1.1703121090.10482068/1.2.276.0.7230010.3.1.4.859333938.1.1703123288.8158915.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120965.10479746/1.2.276.0.7230010.3.1.3.1714512485.1.1703121090.10482068/1.2.276.0.7230010.3.1.4.1714512485.1.1703121090.10482069.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120965.10479746/1.2.276.0.7230010.3.1.3.1714512485.1.1703121090.10482068/1.2.276.0.7230010.3.1.4.811753780.1.1703122771.8353821.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120965.10479746/1.2.276.0.7230010.3.1.3.1714512485.1.1703121090.10482068/1.2.276.0.7230010.3.1.4.859333938.1.1703123250.8158339.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120965.10479746/1.2.276.0.7230010.3.1.3.1714512485.1.1703121090.10482068/1.2.276.0.7230010.3.1.4.845494328.1.1703122732.13486973.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120965.10479746/1.2.276.0.7230010.3.1.3.1714512485.1.1703121090.10482068/1.2.276.0.7230010.3.1.4.845494328.1.1703122909.13489882.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120965.10479746/1.2.276.0.7230010.3.1.3.1714512485.1.1703121090.10482068/1.2.276.0.7230010.3.1.4.811753780.1.1703121894.8340508.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120965.10479746/1.2.276.0.7230010.3.1.3.1714512485.1.1703121090.10482068/1.2.276.0.7230010.3.1.4.845494328.1.1703122820.13488434.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120965.10479746/1.2.276.0.7230010.3.1.3.1714512485.1.1703121090.10482068/1.2.276.0.7230010.3.1.4.845494328.1.1703122711.13486648.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120965.10479746/1.2.276.0.7230010.3.1.3.1714512485.1.1703121090.10482068/1.2.276.0.7230010.3.1.4.845494328.1.1703121706.13470442.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120965.10479746/1.2.276.0.7230010.3.1.3.1714512485.1.1703121090.10482068/1.2.276.0.7230010.3.1.4.1714578744.1.1703122750.8103158.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120965.10479746/1.2.276.0.7230010.3.1.3.1714512485.1.1703121090.10482068/1.2.276.0.7230010.3.1.4.1714578744.1.1703122722.8102782.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120965.10479746/1.2.276.0.7230010.3.1.3.1714512485.1.1703121090.10482068/1.2.276.0.7230010.3.1.4.811753780.1.1703123124.8359335.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120965.10479746/1.2.276.0.7230010.3.1.3.1714512485.1.1703121090.10482068/1.2.276.0.7230010.3.1.4.845494328.1.1703123189.13494660.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120965.10479746/1.2.276.0.7230010.3.1.3.1714512485.1.1703121090.10482068/1.2.276.0.7230010.3.1.4.1714578744.1.1703122973.8106468.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120965.10479746/1.2.276.0.7230010.3.1.3.1714512485.1.1703121090.10482068/1.2.276.0.7230010.3.1.4.811753780.1.1703121287.8330700.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120965.10479746/1.2.276.0.7230010.3.1.3.1714512485.1.1703121090.10482068/1.2.276.0.7230010.3.1.4.1714578744.1.1703123087.8108259.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120965.10479746/1.2.276.0.7230010.3.1.3.1714512485.1.1703121090.10482068/1.2.276.0.7230010.3.1.4.859333938.1.1703123075.8155542.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120965.10479746/1.2.276.0.7230010.3.1.3.1714512485.1.1703121090.10482068/1.2.276.0.7230010.3.1.4.1714578744.1.1703122941.8105984.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120965.10479746/1.2.276.0.7230010.3.1.3.1714512485.1.1703121090.10482068/1.2.276.0.7230010.3.1.4.811753780.1.1703122963.8356787.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120965.10479746/1.2.276.0.7230010.3.1.3.1714512485.1.1703121090.10482068/1.2.276.0.7230010.3.1.4.845494328.1.1703122916.13490003.mp4\\', \\'s3://echodata25/results/echo-study/1.2.276.0.7230010.3.1.2.1714512485.1.1703120965.10479746/1.2.276.0.7230010.3.1.3.1714512485.1.1703121090.10482068/1.2.276.0.7230010.3.1.4.845494328.1.1703123060.13492509.mp4\\']\", \"salient_views\": \"[\\'plax\\', \\'psax-av\\', \\'plax\\', \\'plax\\', \\'plax\\', \\'plax\\', \\'psax-av\\', \\'plax\\', \\'plax\\', \\'a3c\\', \\'a3c\\', \\'plax\\', \\'psax-av\\', \\'a3c\\', \\'psax-av\\', \\'psax-pm\\', \\'plax\\', \\'psax-av\\', \\'plax\\', \\'plax\\', \\'plax\\', \\'psax-av\\', \\'a5c\\', \\'a3c\\', \\'a4c\\', \\'plax\\', \\'a4c\\', \\'a4c\\', \\'psax-ap\\', \\'a4c\\', \\'psax-pm\\', \\'a5c\\']\", \"conversations\": [{\"from\": \"human\", \"value\": \"<image>\\\\nSummarise any findings that could impact haemodynamics or patient management today.\"}, {\"from\": \"gpt\", \"value\": \"<META_START>\\\\n<aortic_root_ascending_aorta_size_mild> <aortic_stenosis_none> <ivc_respiratory_collapse_gt_50> <left_atrial_size_severe> <left_ventricular_cavity_size_mild> <left_ventricular_hypertrophy_asymmetric> <left_ventricular_systolic_function_normal> <pericardial_effusion_none> <right_atrial_size_mild> <mitral_e_e_prime_ratio> 17.2 <right_ventricular_systolic_pressure> 16.0 <right_ventricular_fractional_area_change> 15.7 <left_atrial_volume_index> 158.0 <left_ventricular_ejection_fraction> 72.0 <left_ventricular_end_systolic_volume_index> 75.0 <left_ventricular_mass_index> 170.0\\\\n<META_END>\\\\n\\\\nThe study reveals moderate to severe aortic regurgitation, hypertrophic cardiomyopathy, and a severely dilated left atrium. These findings could significantly impact haemodynamics and require careful patient management.\"}, {\"from\": \"human\", \"value\": \"Can you describe the aortic regurgitation in more detail?\"}, {\"from\": \"gpt\", \"value\": \"The aortic regurgitation is moderate to severe, primarily originating from the right coronary cusp with likely perforation and mild prolapse. It is posteriorly directed, and there is diastolic flow reversal seen in the descending aorta. This regurgitation would appear as a significant jet of blood flowing backward from the aorta into the left ventricle during diastole.\"}, {\"from\": \"human\", \"value\": \"What are the implications of the hypertrophic cardiomyopathy?\"}, {\"from\": \"gpt\", \"value\": \"Hypertrophic cardiomyopathy, as seen in this study, involves asymmetric septal hypertrophy. This condition can lead to left ventricular outflow tract obstruction and diastolic dysfunction. The thickened septum would be visually apparent, potentially causing a narrowing of the outflow tract and affecting ventricular filling.\"}, {\"from\": \"human\", \"value\": \"Is there any evidence of pulmonary hypertension?\"}, {\"from\": \"gpt\", \"value\": \"<UNCERTAIN> The right ventricular systolic pressure (RVSP) is estimated at 16 mmHg, which is within normal limits. However, the study quality is fair, and the tricuspid regurgitant jet is not clearly visible in these views to estimate RVSP accurately. Therefore, I cannot definitively rule out pulmonary hypertension based on these images alone.\"}, {\"from\": \"human\", \"value\": \"What recommendations would you suggest based on these findings?\"}, {\"from\": \"gpt\", \"value\": \"Given the moderate to severe aortic regurgitation and hypertrophic cardiomyopathy, further evaluation by a cardiologist is recommended. Management may include medical therapy to reduce symptoms and prevent complications, and in some cases, surgical intervention might be necessary. Regular follow-up is essential to monitor the progression of these conditions.\"}]}']\n"
     ]
    }
   ],
   "source": [
    "# after the cleaning loop, before the S3 upload\n",
    "num_lines = sum(1 for _ in open(DST))\n",
    "print(\"👀 final jsonl rows:\", num_lines)\n",
    "print(\"first two rows:\\n\", open(DST).read().splitlines()[:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cf35487a-8c89-4c68-8887-9c36f4f7c964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploading to s3://echodata25/BIMBA-LLaVA-NeXT/mlv_1.jsonl …\n",
      "✓ upload complete\n"
     ]
    }
   ],
   "source": [
    "# ─── upload the cleaned file as-is ───────────────────────────────────\n",
    "print(f\"uploading to s3://{S3_BUCKET}/{S3_KEY} …\")\n",
    "boto3.client(\"s3\").upload_file(str(DST), S3_BUCKET, S3_KEY)\n",
    "print(\"✓ upload complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c95cbbc-b391-4e1d-a92f-78846cb26074",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.telemetry.telemetry_logging:SageMaker Python SDK will collect telemetry to help us better understand our user's needs, diagnose issues, and deliver additional features.\n",
      "To opt out of telemetry, please disable via TelemetryOptOut parameter in SDK defaults config. For more information, refer to https://sagemaker.readthedocs.io/en/stable/overview.html#configuring-and-using-defaults-with-the-sagemaker-python-sdk.\n",
      "INFO:sagemaker:Creating training-job with name: bimba-train-2025-05-15-17-56-40-383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-15 18:04:57 Starting - Starting the training job\n",
      "2025-05-15 18:04:57 Pending - Training job waiting for capacity........"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from sagemaker.pytorch import PyTorch\n",
    "import sagemaker, boto3\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# 👇  we’re already inside the BIMBA folder, so just use cwd()\n",
    "SRC_DIR = Path.cwd()                         # /home/.../user-default-efs/BIMBA\n",
    "REQ_FILE = SRC_DIR / \"BIMBA-LLaVA-NeXT\" / \"requirements.txt\"\n",
    "IMAGE_URI = \"495467399120.dkr.ecr.us-west-2.amazonaws.com/bimba-train:latest\"\n",
    "\n",
    "estimator = PyTorch(\n",
    "    image_uri        = IMAGE_URI,\n",
    "    entry_point      = \"train_entrypoint.py\",   # file is right here\n",
    "    source_dir       = str(SRC_DIR),            # <-- fixed path\n",
    "    dependencies     = [str(REQ_FILE)],\n",
    "    role             = role,\n",
    "    instance_type    = \"ml.p4d.24xlarge\", # ml.g5.2xlarge, ml.p4d.24xlarge, ml.p4de.24xlarge, ml.p5.48xlarge\n",
    "    instance_count   = 1,\n",
    "    framework_version = \"2.1\",\n",
    "    py_version       = \"py310\",\n",
    "    base_job_name    = \"bimba-train\",\n",
    "    disable_profiler = True,\n",
    ")\n",
    "\n",
    "estimator.fit(\n",
    "    inputs = {\n",
    "        \"training\": \"s3://echodata25/BIMBA-LLaVA-NeXT/mlv_1.jsonl\"\n",
    "    },\n",
    "    wait   = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c22532-691e-47bd-9a34-4805fdf6887a",
   "metadata": {},
   "source": [
    "# Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ee73e4e3-2119-4b79-af42-05a78ae39f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.telemetry.telemetry_logging:SageMaker Python SDK will collect telemetry to help us better understand our user's needs, diagnose issues, and deliver additional features.\n",
      "To opt out of telemetry, please disable via TelemetryOptOut parameter in SDK defaults config. For more information, refer to https://sagemaker.readthedocs.io/en/stable/overview.html#configuring-and-using-defaults-with-the-sagemaker-python-sdk.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from sagemaker.pytorch import PyTorch\n",
    "import sagemaker, boto3\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# 👇  we’re already inside the BIMBA folder, so just use cwd()\n",
    "SRC_DIR = Path.cwd()                         # /home/.../user-default-efs/BIMBA\n",
    "REQ_FILE = SRC_DIR / \"BIMBA-LLaVA-NeXT\" / \"requirements.txt\"\n",
    "IMAGE_URI = \"495467399120.dkr.ecr.us-west-2.amazonaws.com/bimba-train:latest\"\n",
    "\n",
    "estimator = PyTorch(\n",
    "    image_uri        = IMAGE_URI,\n",
    "    entry_point      = \"train_entrypoint.py\",   # file is right here\n",
    "    source_dir       = str(SRC_DIR),            # <-- fixed path\n",
    "    dependencies     = [str(REQ_FILE)],\n",
    "    role             = role,\n",
    "    instance_type    = \"local\", # ml.g5.2xlarge, ml.p4d.24xlarge, ml.p4de.24xlarge, ml.p5.48xlarge\n",
    "    instance_count   = 1,\n",
    "    framework_version = \"2.1\",\n",
    "    py_version       = \"py310\",\n",
    "    base_job_name    = \"bimba-train\",\n",
    "    disable_profiler = True,\n",
    ")\n",
    "\n",
    "estimator.fit(\n",
    "    inputs = {\n",
    "        \"training\": \"s3://echodata25/BIMBA-LLaVA-NeXT/mlv_1.jsonl\"\n",
    "    },\n",
    "    wait   = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb1cb45-919e-4bd2-b9b9-13ba1c007978",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
